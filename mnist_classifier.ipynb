{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 143.4504, Accuracy: 0.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in log\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 12.0272, Accuracy: 0.6194\n",
      "Epoch 20, Loss: 7.9823, Accuracy: 0.7107\n",
      "Epoch 30, Loss: 6.3898, Accuracy: 0.7513\n",
      "Epoch 40, Loss: 5.4508, Accuracy: 0.7746\n",
      "Epoch 50, Loss: 4.8079, Accuracy: 0.7905\n",
      "Epoch 60, Loss: 4.3304, Accuracy: 0.8030\n",
      "Epoch 70, Loss: 3.9562, Accuracy: 0.8125\n",
      "Epoch 80, Loss: 3.6526, Accuracy: 0.8206\n",
      "Epoch 90, Loss: 3.3994, Accuracy: 0.8263\n",
      "Epoch 100, Loss: 3.1842, Accuracy: 0.8320\n",
      "Epoch 110, Loss: 2.9984, Accuracy: 0.8363\n",
      "Epoch 120, Loss: 2.8357, Accuracy: 0.8408\n",
      "Epoch 130, Loss: 2.6912, Accuracy: 0.8442\n",
      "Epoch 140, Loss: 2.5626, Accuracy: 0.8471\n",
      "Epoch 150, Loss: 2.4472, Accuracy: 0.8497\n",
      "Epoch 160, Loss: 2.3424, Accuracy: 0.8527\n",
      "Epoch 170, Loss: 2.2469, Accuracy: 0.8554\n",
      "Epoch 180, Loss: 2.1595, Accuracy: 0.8579\n",
      "Epoch 190, Loss: 2.0793, Accuracy: 0.8600\n",
      "Epoch 200, Loss: 2.0055, Accuracy: 0.8620\n",
      "Epoch 210, Loss: 1.9371, Accuracy: 0.8638\n",
      "Epoch 220, Loss: 1.8733, Accuracy: 0.8658\n",
      "Epoch 230, Loss: 1.8137, Accuracy: 0.8672\n",
      "Epoch 240, Loss: 1.7578, Accuracy: 0.8684\n",
      "Epoch 250, Loss: 1.7053, Accuracy: 0.8695\n",
      "Epoch 260, Loss: 1.6558, Accuracy: 0.8711\n",
      "Epoch 270, Loss: 1.6092, Accuracy: 0.8724\n",
      "Epoch 280, Loss: 1.5654, Accuracy: 0.8736\n",
      "Epoch 290, Loss: 1.5239, Accuracy: 0.8747\n",
      "Epoch 300, Loss: 1.4845, Accuracy: 0.8759\n",
      "Epoch 310, Loss: 1.4471, Accuracy: 0.8772\n",
      "Epoch 320, Loss: 1.4117, Accuracy: 0.8780\n",
      "Epoch 330, Loss: 1.3782, Accuracy: 0.8789\n",
      "Epoch 340, Loss: 1.3463, Accuracy: 0.8799\n",
      "Epoch 350, Loss: 1.3160, Accuracy: 0.8808\n",
      "Epoch 360, Loss: 1.2871, Accuracy: 0.8816\n",
      "Epoch 370, Loss: 1.2594, Accuracy: 0.8820\n",
      "Epoch 380, Loss: 1.2330, Accuracy: 0.8827\n",
      "Epoch 390, Loss: 1.2076, Accuracy: 0.8835\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # Import TensorFlow library\n",
    "from tensorflow.keras.datasets import mnist  # Import MNIST dataset from Keras\n",
    "from tensorflow.keras.utils import to_categorical  # Import function for one-hot encoding of labels\n",
    "\n",
    "# Load MNIST dataset and split into training and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "\n",
    "# Reshape the images to a flat vector of size 28*28 (784) for each image\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# Convert the labels into one-hot encoded vectors (10 categories)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "import numpy as np  # Import NumPy library for numerical operations\n",
    "\n",
    "# Initialize weights for the neural network (random values for the first layer)\n",
    "w1 = np.random.randn(28 * 28, 128)  # Weights for the first layer (784 input nodes, 128 hidden nodes)\n",
    "b1 = np.zeros((1, 128))  # Bias for the first layer (128 hidden nodes)\n",
    "\n",
    "# Initialize weights for the second layer (128 hidden nodes, 10 output nodes)\n",
    "w2 = np.random.randn(128, 10)  # Weights for the second layer (128 hidden nodes, 10 output nodes)\n",
    "b2 = np.zeros((1, 10))  # Bias for the second layer (10 output nodes)\n",
    "\n",
    "epochs = 400  # Set the number of training epochs (iterations)\n",
    "for epoch in range(epochs):  # Loop through each epoch\n",
    "    # Forward pass for the first layer (linear transformation + activation function)\n",
    "    z1 = x_train @ w1 + b1  # Linear combination of input and weights, plus bias\n",
    "    z1 = np.maximum(0, z1)  # ReLU activation function (set all negative values to 0)\n",
    "\n",
    "    # Forward pass for the second layer (linear transformation)\n",
    "    z2 = z1 @ w2 + b2  # Linear combination of hidden layer output and second layer weights, plus bias\n",
    "\n",
    "    # Softmax function to calculate probabilities for each class\n",
    "    y_pred = np.exp(z2) / np.sum(np.exp(z2), axis=1, keepdims=True)  # Softmax activation\n",
    "\n",
    "    # Compute the loss (cross-entropy loss)\n",
    "    loss = -np.sum(y_train * np.log(y_pred)) / y_train.shape[0]  # Compute the average cross-entropy loss\n",
    "\n",
    "    # Backpropagation to compute gradients (error propagation from output to input)\n",
    "    dz2 = y_pred - y_train  # Gradient of loss with respect to z2\n",
    "    dw2 = np.dot(z1.T, dz2) / y_train.shape[0]  # Gradient of loss with respect to w2\n",
    "    db2 = np.sum(dz2, axis=0, keepdims=True) / y_train.shape[0]  # Gradient of loss with respect to b2\n",
    "\n",
    "    # Backpropagation to the first layer\n",
    "    dz1 = np.dot(dz2, w2.T) * (z1 > 0)  # Gradient of loss with respect to z1 (ReLU derivative)\n",
    "    dw1 = np.dot(x_train.T, dz1) / x_train.shape[0]  # Gradient of loss with respect to w1\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True) / x_train.shape[0]  # Gradient of loss with respect to b1\n",
    "\n",
    "    learning_rate = 0.2  # Set the learning rate (step size for gradient descent)\n",
    "\n",
    "    # Update the weights and biases using gradient descent\n",
    "    w1 -= learning_rate * dw1  # Update weights for the first layer\n",
    "    b1 -= learning_rate * db1  # Update biases for the first layer\n",
    "    w2 -= learning_rate * dw2  # Update weights for the second layer\n",
    "    b2 -= learning_rate * db2  # Update biases for the second layer\n",
    "\n",
    "    # Print the loss and accuracy every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)  # Get predicted labels by choosing the max probability\n",
    "        y_true_labels = np.argmax(y_train, axis=1)  # Get true labels (original labels)\n",
    "        accuracy = np.mean(y_pred_labels == y_true_labels)  # Calculate accuracy\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")  # Print epoch info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample = x_test[760].reshape(1, -1)  \n",
    "z1 = sample @ w1 + b1\n",
    "z1 = np.maximum(0, z1)  # ReLU\n",
    "z2 = z1 @ w2 + b2\n",
    "y_pred = np.exp(z2) / np.sum(np.exp(z2), axis=1, keepdims=True)\n",
    "predicted_label = np.argmax(y_pred)\n",
    "print(predicted_label)\n",
    "plt.imshow(x_test[760].reshape(28, 28), cmap='gray')\n",
    "print(x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
